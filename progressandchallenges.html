<!DOCTYPE html>
<html lang="en">
 <head>
    <title>Progress & Challenges</title>
    <link rel="stylesheet" href="style.css">
 </head>
 <body>
 <header>
        <h3>CS1102 Project (2024-2025 Sem B)</h3>
        <h2>Project Group for Topic 3a</h2>
        <h1>Public Opinion Analysis in the Era of Big Data</h1>
        <div>
            <nav>
                <a href="CS1102_Text_File.pdf" target="_blank">Project Text File</a>
                <a href="Video_Complete.MP4">Project Video</a>
            </nav>
            <br>
        </div>
        <div>
            <hr>
            <nav>
                <a href="index.html">Introduction</a>
                <a href="theories.html">Theories</a>
                <a href="#" class="open">Progress & Challenges</a>
                <a href="solutions.html">Our Solutions</a>
                <a href="interact.html">Sentiment Analysis</a>
                <a href="references.html">References</a>
            </nav>
            <hr>
        </div>
    </header>
 <h2>Progress & Challenges</h2>
 <p> Nowadays, with the development of big data, which does not only refer to the mass of data but also includes abundant amounts of data and extensive data processing methods, network information becomes vast and diverse. This has promoted the emergence of online public opinion, which is also seen as a reflec- tion of the big data era. Rather than that, it also symbolizes the presence by the relevant technical after extracting and analyzing the results coming from a massive network data. In order to achieve a thorough analysis, a network public opinion analysis platform was designed and could be generally divided into 5 steps: information collection, data mining and processing, data storage, public opinion analysis and data security. </p>
 <h3>Information Collection</h3>
 <p> Web crawler tool is used in the Internet page document information in real-life collection. This tool is an automated system crawling web content, which consists of a service controller, a task allocator, and multiple crawler clients. The service controller helps to connect to the client and control the crawl time of each client. The task allocator assists to assign a crawl task to each client. Web crawling supports the collection of web pages documents including news, forums, web documents and blog Web documents, since all these documents contain many HTML tags. The processing power of web crawlers often impacts on the scalability and performance of a searching engine. </p>
 <h3>Data mining and processing</h3>
 <p> Data mining is to study advanced and in- telligent data processing. It helps to transform the valuable information content into formatted information text, which considerably facilitates the subsequent operations. To achieve this goal, first of all, the system will deduplicate the information, remove the noise, and strip the non-valuable web page information. Then, a technique called word segmentation is applied to cut the text string into the term information, which are defined as the feature items of the text. Last but not the least, a series of different mathematical models, including vector space model, probability model, etc., are used to extract feature records from feature items to form a text vector set. </p>
 <h3>Data storage</h3>
 <p> With the rapid growth of computer technol- ogy, the most advanced and developed storage technology acknowledged is cloud storage. </p>
 <h3>Public Opinion Analysis</h3>
 <p> This is the core module of the entire plat- form. From the database, hidden information with potential value is refined and aggregated for the purpose of sensing topics recognition, topic tracking, text orientation analysis, hotspot mining, and hotspot predicting. In order to determine the primary topic of a document, nu- merous documents pertaining to the same event are clustered using topic recognition, which is machine learning of a collection of text vectors.
Topic tracking determines whether a text is related to an existing topic by calculating how similar each new vectorized text is to the previ- ous one. The text is categorized under this topic if it is pertinent, and as a new topic if it is not. By computer mining non-content or non-fact information, such as different points of view, preferences, attitudes, and emotions present in the networkâ€™s text content, text orientation analysis can extract text semantics. Assist the appropriate departments in promptly identify- ing negative complaints. Monitoring the exca- vated areas and determining that the amount of propagation within the predetermined standard period surpasses the critical value is the goal of hotspot mining. It is concluded that the subject has become overly popular and should be expanded. Hotspot prediction is based on hotspot mining results, which are obtained by combining topic categories, topic content, pub- lic sentiments, and other factors with similar events in the database. predicting the future traffic volume curve for popular subjects. </p>
 <h3>Data security</h3>
 <p> Along with the development of the era of big data, a large amount of data generated greatly increased the risk of confidence leak- age. Protecting the privacy and safety of data has become the main task and this is also the one of the greatest challenges for many platforms. </p>
 <h3>Case Study: Facebook-Cambridge Analytica Data Scandal</h3>
 <p> Using big data to analyze public opinion could lead to potential backlashes such as vio- lation of privacy. In 2018, Cambridge Analyt- ica, a political consulting firm, was revealed by whistleblowers. It was found to collect users' personal data without consent through an app called "This is your digital life". It was accused of profiling users based on their ideology and manipulating campaign including 2016 U.S. Presidential campaign and the Brexit though the information collected on Facebook, one of the world's biggest social media firms (Chan, 2019). As a result, Facebook was fined $5 billion by the Federal Trade Commission on account of the violation of privacy (The Guardian, 2019). </p>
 </body>
</html>